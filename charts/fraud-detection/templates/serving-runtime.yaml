# apiVersion: serving.kserve.io/v1alpha1
# kind: ServingRuntime
# metadata:
#   annotations:
#     openshift.io/display-name: ONNX ServingRuntime for KServe
#   labels:
#     opendatahub.io/dashboard: "true"
#   name: onnx-runtime
# spec:
#   annotations:
#     prometheus.io/path: /metrics
#     prometheus.io/port: "8080"
#   containers :
#     - args:
#       - --port=8080
#       - --model=/mnt/models
#       - --served-model-name={{.Name}}
#       command:
#         - python
#         - '-m'
#         - vllm.entrypoints.openai.api_server
#       env:
#         - name: HF_HOME
#           value: /tmp/hf_home
#       image: quay.io/modh/vllm@sha256:8a3dd8ad6e15fe7b8e5e471037519719d4d8ad3db9d69389f2beded36a6f5b21
#       name: kserve-container
#       ports:
#         - containerPort: 8080
#           protocol: TCP
#   multiModel: false
#   supportedModelFormats:
#     - autoSelect: true
#       name: onnx
